{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CUiLU2CT-tb6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5Qqh9AfS-8ai"
   },
   "outputs": [],
   "source": [
    "ko_1_size = 15\n",
    "wt_1_size = 15\n",
    "ko_2_size = 41\n",
    "wt_2_size = 41\n",
    "ko_3_size = 16\n",
    "wt_3_size = 18\n",
    "\n",
    "ko_1_file_prefix = '1KO'\n",
    "wt_1_file_prefix = '1WT'\n",
    "ko_2_file_prefix = '2KO'\n",
    "wt_2_file_prefix = '2WT'\n",
    "ko_3_file_prefix = '3KO'\n",
    "wt_3_file_prefix = '3WT'\n",
    "\n",
    "ko_mice_symbol = 0\n",
    "wt_mice_symbol = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trail_num = 1280\n",
    "learning_rate = 0.0001\n",
    "reduce_lr_factor = 0.5\n",
    "reduce_lr_patience = 5\n",
    "min_learning_rate = 0.00001\n",
    "early_stopping_patience = 10\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "metric_cut_percent = 0.2\n",
    "metric_lower_cut_percent = 0.2\n",
    "metric_upper_cut_percent = 0.2\n",
    "noise_deviation = 0.00005\n",
    "data_augmentation_factor = 3\n",
    "step_size = 40\n",
    "test_data_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8E4RgKo-8d1",
    "outputId": "49357805-0bbf-4bd7-eb1b-2ae407a7d135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KO data dir exists: True\n",
      "WT data dir exists: True\n"
     ]
    }
   ],
   "source": [
    "ko_directory = r'/data/KO/'\n",
    "wt_directory = r'/data/WT/'\n",
    "print('KO data dir exists: ' + str(os.path.exists(ko_directory)))\n",
    "print('WT data dir exists: ' + str(os.path.exists(wt_directory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0wkZDdks-8gD"
   },
   "outputs": [],
   "source": [
    "def read_x_data(file_dir, data_size, file_prefix):\n",
    "    train_x = []\n",
    "    train_record = []\n",
    "    for i in range(data_size):\n",
    "        train_x.append(pd.read_excel(os.path.join(file_dir, file_prefix + str(i+1) + '.xlsx'), dtype='int16', header=None, sheet_name='Sheet1'))\n",
    "        train_record.append(pd.read_excel(os.path.join(file_dir, file_prefix + str(i+1) + '.xlsx'), dtype='int16', header=None, sheet_name='Sheet2'))\n",
    "\n",
    "    return train_x, train_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsample(data, time_factor=2):\n",
    "#     \"\"\"\n",
    "#     input shape： (n_samples, trails, timesteps, features)\n",
    "#     output shape： (n_samples, trails, timesteps//factor, features)\n",
    "#     \"\"\"\n",
    "#     return data[:, ::time_factor, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_pre_process(behavior_data_list, record_data_list, with_noise):\n",
    "    data_size = len(behavior_data_list)\n",
    "    pre_processed_data = []\n",
    "    \n",
    "    for i in range(data_size):\n",
    "        behavior_data = np.expand_dims(behavior_data_list[i].values[:, 200:1000], axis=-1)\n",
    "        record_data = record_data_list[i]\n",
    "        operation_data = record_data.loc[0]\n",
    "        odor1_data = np.zeros((behavior_data.shape[0], behavior_data.shape[1], 1))\n",
    "        odor2_data = np.zeros((behavior_data.shape[0], behavior_data.shape[1], 1))\n",
    "        reward_data = np.zeros((behavior_data.shape[0], behavior_data.shape[1], 1))\n",
    "        cur_trail_count_data = np.zeros((behavior_data.shape[0], behavior_data.shape[1], 1))\n",
    "        trail_count_data = np.zeros((behavior_data.shape[0], behavior_data.shape[1], 1))\n",
    "        \n",
    "        sum_trail_count = operation_data.shape[0]\n",
    "        for j in range(sum_trail_count):\n",
    "            lick_data = behavior_data[j]\n",
    "            trail_result = -1\n",
    "            odor = -1\n",
    "\n",
    "            if(operation_data[j]==1):\n",
    "                odor = 2\n",
    "                odor2_data[j, 0:100, :] = 1\n",
    "\n",
    "                # search lick index\n",
    "                lick_index = -1\n",
    "                for k in range(300,500):\n",
    "                    if(lick_data[k][0] == 1):\n",
    "                        lick_index = k\n",
    "                        break\n",
    "\n",
    "                if(lick_index > 0):\n",
    "                    reward_data[j, (lick_index +1):(lick_index + 51), :] = 1\n",
    "                    trail_result = 1\n",
    "                else:\n",
    "                    trail_result = 2\n",
    "            else:\n",
    "                odor = 1\n",
    "                odor1_data[j, 0:100, :] = 1\n",
    "\n",
    "                # search lick index\n",
    "                lick_index = -1\n",
    "                for k in range(0,600):\n",
    "                    if(lick_data[k]==1):\n",
    "                        lick_index = k\n",
    "                        break\n",
    "\n",
    "                # append result data\n",
    "                if(lick_index>0):\n",
    "                    trail_result = 3\n",
    "                else:\n",
    "                    trail_result = 4\n",
    "\n",
    "            cur_trail_count_data[j, :, :] = (j + 1) / sum_trail_count\n",
    "        \n",
    "        trail_count_data[:sum_trail_count, :, :] = sum_trail_count / 1850.0\n",
    "        x_data = np.concatenate((behavior_data, odor1_data, odor2_data, reward_data, cur_trail_count_data, trail_count_data), axis=2)\n",
    "        \n",
    "        if with_noise:\n",
    "            noise = np.random.normal(0, noise_deviation, x_data.shape)\n",
    "            x_data += noise\n",
    "\n",
    "        pre_processed_data.append(x_data)\n",
    "        \n",
    "    return pre_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_x_data(file_dir, data_size, file_prefix, with_noise):\n",
    "    lick_data, record_data = read_x_data(file_dir, data_size, file_prefix)\n",
    "    pre_processed_data = train_data_pre_process(lick_data, record_data, with_noise)\n",
    "    return pre_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_x_data(x_data_list, max_trail_count):\n",
    "    padded_x_data_list = []\n",
    "    for x_data in x_data_list:\n",
    "        if max_trail_count > len(x_data):\n",
    "            padding_size = max_trail_count - len(x_data)\n",
    "            padded = np.zeros((padding_size, x_data.shape[1], x_data.shape[2]))\n",
    "            padded_x_data = np.concatenate((x_data, padded), axis=0)\n",
    "            padded_x_data_list.append(padded_x_data)\n",
    "        else:\n",
    "            padded_x_data_list.append(x_data[:max_trail_count, :, :]) \n",
    "            \n",
    "    return padded_x_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_x_y(ko_x_data, wt_x_data, split=0.2):\n",
    "    ko_data_length = len(ko_x_data)\n",
    "    wt_data_length = len(wt_x_data)\n",
    "    ko_y_data = np.zeros(ko_data_length)\n",
    "    ko_y_data[:] = ko_mice_symbol\n",
    "    wt_y_data = np.zeros(wt_data_length)\n",
    "    wt_y_data[:] = wt_mice_symbol\n",
    "    \n",
    "    ko_split = int(ko_data_length * (1 - split))\n",
    "    wt_split = int(wt_data_length * (1 - split))\n",
    "    \n",
    "    ko_x_data = np.array(ko_x_data)\n",
    "    wt_x_data = np.array(wt_x_data)\n",
    "    \n",
    "    train_x = np.concatenate([ko_x_data[:ko_split], wt_x_data[:wt_split]])\n",
    "    train_y = np.concatenate([ko_y_data[:ko_split], wt_y_data[:wt_split]])\n",
    "    \n",
    "    val_x = np.concatenate([ko_x_data[ko_split:], wt_x_data[wt_split:]])\n",
    "    val_y = np.concatenate([ko_y_data[ko_split:], wt_y_data[wt_split:]])\n",
    "    \n",
    "    x_data = np.concatenate([train_x, val_x])\n",
    "    y_data = np.concatenate([train_y, val_y])\n",
    "    \n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_max_trail_count(data_array):\n",
    "    return max([data.shape[0] for data in data_array]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sliding_window_size(x_data, augmentation_factor, step_size):\n",
    "    trail_nums = [x.shape[0] for x in x_data]\n",
    "    max_trail_num = max(trail_nums)\n",
    "    if augmentation_factor <= 1:\n",
    "        return max_trail_num\n",
    "    return max_trail_num - (augmentation_factor - 1) * step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(x_data, y_data, window_size, step_size, augmentation_factor):\n",
    "    x_data_augmented = []\n",
    "    y_data_augmented = np.repeat(y_data, max(1, augmentation_factor))\n",
    "    if augmentation_factor <= 1:\n",
    "        return x_data, y_data_augmented\n",
    "    for i in range(x_data.shape[0]):\n",
    "        for j in range(0, x_data.shape[1] - window_size + 1, step_size):\n",
    "            single_window = x_data[i, j:j + window_size, :, :]\n",
    "            x_data_augmented.append(single_window)\n",
    "        \n",
    "    return np.array(x_data_augmented), y_data_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_trail_count(x_data_list):\n",
    "    max_trail_count = 0\n",
    "    for x_data in x_data_list:\n",
    "        cur_trail_count = x_data.shape[0]\n",
    "        if cur_trail_count > max_trail_count:\n",
    "            max_trail_count = cur_trail_count\n",
    "    return max_trail_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_lists(*lists):\n",
    "    for lst in lists:\n",
    "        random.shuffle(lst)\n",
    "\n",
    "def interleave_lists(list1, list2, list3):\n",
    "    len1, len2, len3 = len(list1), len(list2), len(list3)\n",
    "    \n",
    "    total_length = len1 + len2 + len3\n",
    "    \n",
    "    weight1 = len1 / total_length\n",
    "    weight2 = len2 / total_length\n",
    "    weight3 = len3 / total_length\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    used1 = used2 = used3 = 0\n",
    "    \n",
    "    while used1 + used2 + used3 < total_length:\n",
    "        ideal1 = (used1 + used2 + used3 + 1) * weight1\n",
    "        ideal2 = (used1 + used2 + used3 + 1) * weight2\n",
    "        ideal3 = (used1 + used2 + used3 + 1) * weight3\n",
    "        \n",
    "        diff1 = ideal1 - used1 if used1 < len1 else float('-inf')\n",
    "        diff2 = ideal2 - used2 if used2 < len2 else float('-inf')\n",
    "        diff3 = ideal3 - used3 if used3 < len3 else float('-inf')\n",
    "        \n",
    "        max_diff = max(diff1, diff2, diff3)\n",
    "        \n",
    "        if max_diff == diff1:\n",
    "            result.append(list1[used1])\n",
    "            used1 += 1\n",
    "        elif max_diff == diff2:\n",
    "            result.append(list2[used2])\n",
    "            used2 += 1\n",
    "        else:\n",
    "            result.append(list3[used3])\n",
    "            used3 += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_1_x_data = get_preprocessed_x_data(ko_directory, ko_1_size, ko_1_file_prefix, True)\n",
    "wt_1_x_data = get_preprocessed_x_data(wt_directory, wt_1_size, wt_1_file_prefix, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_2_x_data = get_preprocessed_x_data(ko_directory, ko_2_size, ko_2_file_prefix, True)\n",
    "wt_2_x_data = get_preprocessed_x_data(wt_directory, wt_2_size, wt_2_file_prefix, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_3_x_data = get_preprocessed_x_data(ko_directory, ko_3_size, ko_3_file_prefix, True)\n",
    "wt_3_x_data = get_preprocessed_x_data(wt_directory, wt_3_size, wt_3_file_prefix, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_x_data = interleave_lists(ko_1_x_data, ko_2_x_data, ko_3_x_data)\n",
    "\n",
    "wt_x_data = interleave_lists(wt_1_x_data, wt_2_x_data, wt_3_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_data_len = len(ko_x_data)\n",
    "wt_data_len = len(wt_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_ko_x_data = padding_x_data(ko_x_data, max_trail_num)\n",
    "padded_wt_x_data = padding_x_data(wt_x_data, max_trail_num)\n",
    "all_x_data_list = padded_ko_x_data + padded_wt_x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = get_model_x_y(padded_ko_x_data, padded_wt_x_data, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 1280, 800, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = get_sliding_window_size(x_data, data_augmentation_factor, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = sliding_windows(x_data, y_data, window_size, step_size, data_augmentation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ko_1_x_data\n",
    "del wt_1_x_data\n",
    "del ko_2_x_data\n",
    "del wt_2_x_data\n",
    "del ko_3_x_data\n",
    "del wt_3_x_data\n",
    "\n",
    "del ko_x_data\n",
    "del wt_x_data\n",
    "\n",
    "del padded_ko_x_data\n",
    "del padded_wt_x_data\n",
    "del all_x_data_list\n",
    "\n",
    "del x_data\n",
    "del y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 1200, 800, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, TimeDistributed, LSTM, GlobalAveragePooling1D, Flatten, Bidirectional, GRU, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import AdamW\n",
    "# keras.optimizers.Adam runs slowly on M1,M2, so use keras.optimizers.legacy.Adam instead\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.regularizers import l1, l2\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def get_sorted_error_sliced(y_true, y_pred):\n",
    "    \n",
    "    error = K.abs(y_pred - y_true)\n",
    "    error_transpose = tf.transpose(error)\n",
    "    sorted_error = tf.sort(error_transpose)\n",
    "    \n",
    "    num_samples = tf.shape(sorted_error)[1]\n",
    "    num_to_remove = num_samples // 5\n",
    "    \n",
    "    sorted_error_sliced = sorted_error[:, :-num_to_remove]\n",
    "    \n",
    "    return sorted_error_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def custom_error(y_true, y_pred):\n",
    "    \n",
    "    sorted_error_sliced = get_sorted_error_sliced(y_true, y_pred)\n",
    "    \n",
    "    mse = K.mean(K.square(sorted_error_sliced))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    sorted_error_sliced = get_sorted_error_sliced(y_true, y_pred)\n",
    "    \n",
    "    correct_predictions = 1 - K.abs(sorted_error_sliced)\n",
    "    \n",
    "    return K.mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(y_true, y_pred):\n",
    "    sorted_error_sliced = get_sorted_error_sliced(y_true, y_pred)\n",
    "\n",
    "    mse = K.mean(K.square(sorted_error_sliced))\n",
    "    \n",
    "    errors = K.abs(sorted_error_sliced)\n",
    "    \n",
    "    weights = K.exp(-K.square(errors))\n",
    "    \n",
    "    weighted_errors = K.square(errors) * weights\n",
    "    \n",
    "    weighted_mse = K.mean(weighted_errors)\n",
    "    \n",
    "    return weighted_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "def custom_binary_crossentropy(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    sorted_indices = tf.argsort(loss, axis=0)\n",
    "    sorted_loss = tf.gather(loss, sorted_indices)\n",
    "    \n",
    "    num_data_points = tf.shape(loss)[0]\n",
    "    num_keep = num_data_points - num_data_points // 5\n",
    "    \n",
    "    reduced_loss = tf.reduce_mean(sorted_loss[:num_keep])\n",
    "    \n",
    "    return reduced_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    return K.mean(1 - K.abs(y_true - K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + 1e-6))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "class MatthewsCorrelationCoefficient(Metric):\n",
    "    def __init__(self, name='mcc', threshold=0.5, **kwargs):\n",
    "        super(MatthewsCorrelationCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true * y_pred)\n",
    "        tn = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        numerator = (self.true_positives * self.true_negatives - \n",
    "                    self.false_positives * self.false_negatives)\n",
    "        \n",
    "        denominator = tf.sqrt(\n",
    "            (self.true_positives + self.false_positives) *\n",
    "            (self.true_positives + self.false_negatives) *\n",
    "            (self.true_negatives + self.false_positives) *\n",
    "            (self.true_negatives + self.false_negatives) + \n",
    "            tf.keras.backend.epsilon()\n",
    "        )\n",
    "        \n",
    "        return numerator / denominator\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric, SpecificityAtSensitivity\n",
    "\n",
    "class BalancedAccuracy(Metric):\n",
    "    def __init__(self, name='balanced_acc', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.recall = Recall()\n",
    "        self.specificity = SpecificityAtSensitivity(0.5)\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "        self.specificity.update_state(y_true, y_pred, sample_weight)\n",
    "        \n",
    "    def result(self):\n",
    "        return (self.recall.result() + self.specificity.result()) / 2\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.recall.reset_states()\n",
    "        self.specificity.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation class distribution: [43 45]\n"
     ]
    }
   ],
   "source": [
    "y_val = y_train[int((1-validation_split) *len(y_train)):]\n",
    "print(\"Validation class distribution:\", np.bincount(y_val.astype(int)))\n",
    "\n",
    "if len(np.unique(y_val)) == 1:\n",
    "    print(\"警告：验证集只有单一类别！需调整数据分割策略\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "from keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028\n",
      "\n",
      "Training Fold 1/5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDist  (None, 1200, 800, 16)     2416      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 1200, 800, 16)     64        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 1200, 200, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 1200, 3200)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1200, 256)         3408896   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 1200, 256)         394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 256)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3822129 (14.58 MB)\n",
      "Trainable params: 3822097 (14.58 MB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - ETA: 0s - loss: 5.9297 - accuracy: 0.6800 - precision: 0.6548 - recall: 0.7457 - auc: 0.7559 - f1_score: 0.6973 - mcc: 0.3644 - balanced_acc: 0.7824 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yzc/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "/Users/yzc/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "/Users/yzc/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:2723: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 152s 13s/step - loss: 5.9297 - accuracy: 0.6800 - precision: 0.6548 - recall: 0.7457 - auc: 0.7559 - f1_score: 0.6973 - mcc: 0.3644 - balanced_acc: 0.7824 - val_loss: 5.8446 - val_accuracy: 0.5795 - val_precision: 0.8333 - val_recall: 0.3061 - val_auc: 0.8655 - val_f1_score: 0.4478 - val_mcc: 0.2823 - val_balanced_acc: 0.5890 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 134s 12s/step - loss: 5.6733 - accuracy: 0.7429 - precision: 0.6912 - recall: 0.8671 - auc: 0.8123 - f1_score: 0.7692 - mcc: 0.5032 - balanced_acc: 0.8516 - val_loss: 5.5766 - val_accuracy: 0.7273 - val_precision: 0.8571 - val_recall: 0.6122 - val_auc: 0.8647 - val_f1_score: 0.7143 - val_mcc: 0.4913 - val_balanced_acc: 0.7420 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 5.4698 - accuracy: 0.7457 - precision: 0.7059 - recall: 0.8324 - auc: 0.8171 - f1_score: 0.7639 - mcc: 0.5003 - balanced_acc: 0.8399 - val_loss: 5.3541 - val_accuracy: 0.7500 - val_precision: 0.8462 - val_recall: 0.6735 - val_auc: 0.8663 - val_f1_score: 0.7500 - val_mcc: 0.5196 - val_balanced_acc: 0.7726 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 5.2975 - accuracy: 0.7000 - precision: 0.6789 - recall: 0.7457 - auc: 0.8049 - f1_score: 0.7107 - mcc: 0.4025 - balanced_acc: 0.8022 - val_loss: 5.1454 - val_accuracy: 0.8182 - val_precision: 0.8667 - val_recall: 0.7959 - val_auc: 0.8660 - val_f1_score: 0.8298 - val_mcc: 0.6381 - val_balanced_acc: 0.8339 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 134s 12s/step - loss: 5.0945 - accuracy: 0.7571 - precision: 0.7268 - recall: 0.8150 - auc: 0.8140 - f1_score: 0.7684 - mcc: 0.5186 - balanced_acc: 0.8256 - val_loss: 4.9546 - val_accuracy: 0.8068 - val_precision: 0.8478 - val_recall: 0.7959 - val_auc: 0.8687 - val_f1_score: 0.8211 - val_mcc: 0.6131 - val_balanced_acc: 0.8467 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 136s 12s/step - loss: 4.9030 - accuracy: 0.7686 - precision: 0.7190 - recall: 0.8728 - auc: 0.8374 - f1_score: 0.7885 - mcc: 0.5506 - balanced_acc: 0.8827 - val_loss: 4.7711 - val_accuracy: 0.8068 - val_precision: 0.8478 - val_recall: 0.7959 - val_auc: 0.8705 - val_f1_score: 0.8211 - val_mcc: 0.6131 - val_balanced_acc: 0.8467 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 135s 12s/step - loss: 4.7473 - accuracy: 0.7543 - precision: 0.7231 - recall: 0.8150 - auc: 0.8150 - f1_score: 0.7663 - mcc: 0.5133 - balanced_acc: 0.8143 - val_loss: 4.6016 - val_accuracy: 0.8182 - val_precision: 0.8667 - val_recall: 0.7959 - val_auc: 0.8744 - val_f1_score: 0.8298 - val_mcc: 0.6381 - val_balanced_acc: 0.8467 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 135s 12s/step - loss: 4.5681 - accuracy: 0.7629 - precision: 0.7184 - recall: 0.8555 - auc: 0.8315 - f1_score: 0.7810 - mcc: 0.5363 - balanced_acc: 0.8599 - val_loss: 4.4223 - val_accuracy: 0.8068 - val_precision: 0.8077 - val_recall: 0.8571 - val_auc: 0.8755 - val_f1_score: 0.8317 - val_mcc: 0.6070 - val_balanced_acc: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 4.4172 - accuracy: 0.7600 - precision: 0.7171 - recall: 0.8497 - auc: 0.8275 - f1_score: 0.7778 - mcc: 0.5298 - balanced_acc: 0.8571 - val_loss: 4.2977 - val_accuracy: 0.7841 - val_precision: 0.8571 - val_recall: 0.7347 - val_auc: 0.8794 - val_f1_score: 0.7912 - val_mcc: 0.5777 - val_balanced_acc: 0.8161 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 131s 12s/step - loss: 4.2664 - accuracy: 0.7486 - precision: 0.7348 - recall: 0.7688 - auc: 0.8330 - f1_score: 0.7514 - mcc: 0.4979 - balanced_acc: 0.8222 - val_loss: 4.1304 - val_accuracy: 0.8409 - val_precision: 0.8723 - val_recall: 0.8367 - val_auc: 0.8864 - val_f1_score: 0.8542 - val_mcc: 0.6800 - val_balanced_acc: 0.8671 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 4.1180 - accuracy: 0.7743 - precision: 0.7350 - recall: 0.8497 - auc: 0.8380 - f1_score: 0.7882 - mcc: 0.5559 - balanced_acc: 0.8627 - val_loss: 3.9824 - val_accuracy: 0.8182 - val_precision: 0.8000 - val_recall: 0.8980 - val_auc: 0.8796 - val_f1_score: 0.8462 - val_mcc: 0.6320 - val_balanced_acc: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 3.9714 - accuracy: 0.7743 - precision: 0.7176 - recall: 0.8960 - auc: 0.8484 - f1_score: 0.7969 - mcc: 0.5671 - balanced_acc: 0.8887 - val_loss: 3.8681 - val_accuracy: 0.8295 - val_precision: 0.8864 - val_recall: 0.7959 - val_auc: 0.8870 - val_f1_score: 0.8387 - val_mcc: 0.6634 - val_balanced_acc: 0.8467 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 131s 12s/step - loss: 3.8540 - accuracy: 0.7600 - precision: 0.7306 - recall: 0.8150 - auc: 0.8420 - f1_score: 0.7705 - mcc: 0.5240 - balanced_acc: 0.8454 - val_loss: 3.7305 - val_accuracy: 0.8068 - val_precision: 0.7759 - val_recall: 0.9184 - val_auc: 0.8773 - val_f1_score: 0.8411 - val_mcc: 0.6131 - val_balanced_acc: 0.9079 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 133s 12s/step - loss: 3.7221 - accuracy: 0.7714 - precision: 0.7360 - recall: 0.8382 - auc: 0.8447 - f1_score: 0.7838 - mcc: 0.5487 - balanced_acc: 0.8541 - val_loss: 3.6123 - val_accuracy: 0.8409 - val_precision: 0.8889 - val_recall: 0.8163 - val_auc: 0.8943 - val_f1_score: 0.8511 - val_mcc: 0.6838 - val_balanced_acc: 0.8569 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 133s 12s/step - loss: 3.5836 - accuracy: 0.7943 - precision: 0.7440 - recall: 0.8902 - auc: 0.8643 - f1_score: 0.8105 - mcc: 0.6008 - balanced_acc: 0.8942 - val_loss: 3.4741 - val_accuracy: 0.8409 - val_precision: 0.8571 - val_recall: 0.8571 - val_auc: 0.8980 - val_f1_score: 0.8571 - val_mcc: 0.6777 - val_balanced_acc: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 3.4629 - accuracy: 0.7857 - precision: 0.7475 - recall: 0.8555 - auc: 0.8757 - f1_score: 0.7978 - mcc: 0.5780 - balanced_acc: 0.8910 - val_loss: 3.3561 - val_accuracy: 0.8636 - val_precision: 0.8364 - val_recall: 0.9388 - val_auc: 0.9079 - val_f1_score: 0.8846 - val_mcc: 0.7265 - val_balanced_acc: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 133s 12s/step - loss: 3.3306 - accuracy: 0.8143 - precision: 0.7596 - recall: 0.9133 - auc: 0.8958 - f1_score: 0.8294 - mcc: 0.6423 - balanced_acc: 0.9171 - val_loss: 3.2304 - val_accuracy: 0.8864 - val_precision: 0.8980 - val_recall: 0.8980 - val_auc: 0.9197 - val_f1_score: 0.8980 - val_mcc: 0.7698 - val_balanced_acc: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 3.2010 - accuracy: 0.8571 - precision: 0.8289 - recall: 0.8960 - auc: 0.9149 - f1_score: 0.8611 - mcc: 0.7168 - balanced_acc: 0.9197 - val_loss: 3.1064 - val_accuracy: 0.8977 - val_precision: 0.8448 - val_recall: 1.0000 - val_auc: 0.9367 - val_f1_score: 0.9159 - val_mcc: 0.8061 - val_balanced_acc: 0.9744 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 128s 12s/step - loss: 3.1104 - accuracy: 0.8571 - precision: 0.7971 - recall: 0.9538 - auc: 0.9249 - f1_score: 0.8684 - mcc: 0.7287 - balanced_acc: 0.9571 - val_loss: 2.9978 - val_accuracy: 0.8977 - val_precision: 0.8704 - val_recall: 0.9592 - val_auc: 0.9351 - val_f1_score: 0.9126 - val_mcc: 0.7955 - val_balanced_acc: 0.9540 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 116s 10s/step - loss: 2.9890 - accuracy: 0.8629 - precision: 0.8205 - recall: 0.9249 - auc: 0.9324 - f1_score: 0.8696 - mcc: 0.7319 - balanced_acc: 0.9398 - val_loss: 2.8868 - val_accuracy: 0.8750 - val_precision: 0.8654 - val_recall: 0.9184 - val_auc: 0.9610 - val_f1_score: 0.8911 - val_mcc: 0.7465 - val_balanced_acc: 0.9592 - lr: 1.0000e-04\n",
      "3/3 [==============================] - 8s 2s/step\n",
      "evaluate result\n",
      "\n",
      "Training Fold 2/5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time_distributed (TimeDist  (None, 1200, 800, 16)     2416      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 1200, 800, 16)     64        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 1200, 200, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 1200, 3200)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1200, 256)         3408896   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 1200, 256)         394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 256)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3822129 (14.58 MB)\n",
      "Trainable params: 3822097 (14.58 MB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 168s 15s/step - loss: 5.9225 - accuracy: 0.7314 - precision: 0.7037 - recall: 0.8352 - auc: 0.7638 - f1_score: 0.7638 - mcc: 0.4668 - balanced_acc: 0.8134 - val_loss: 5.7807 - val_accuracy: 0.7614 - val_precision: 0.8065 - val_recall: 0.6250 - val_auc: 0.8586 - val_f1_score: 0.7042 - val_mcc: 0.5212 - val_balanced_acc: 0.7708 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 150s 13s/step - loss: 5.7343 - accuracy: 0.7486 - precision: 0.7423 - recall: 0.7912 - auc: 0.7995 - f1_score: 0.7660 - mcc: 0.4961 - balanced_acc: 0.8152 - val_loss: 5.6060 - val_accuracy: 0.7386 - val_precision: 0.6545 - val_recall: 0.9000 - val_auc: 0.8594 - val_f1_score: 0.7579 - val_mcc: 0.5185 - val_balanced_acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 156s 14s/step - loss: 5.5523 - accuracy: 0.7600 - precision: 0.7188 - recall: 0.8846 - auc: 0.8048 - f1_score: 0.7931 - mcc: 0.5304 - balanced_acc: 0.8560 - val_loss: 5.4269 - val_accuracy: 0.7500 - val_precision: 0.6875 - val_recall: 0.8250 - val_auc: 0.8604 - val_f1_score: 0.7500 - val_mcc: 0.5125 - val_balanced_acc: 0.8813 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 149s 13s/step - loss: 5.3989 - accuracy: 0.7229 - precision: 0.7033 - recall: 0.8077 - auc: 0.8051 - f1_score: 0.7519 - mcc: 0.4468 - balanced_acc: 0.8324 - val_loss: 5.2845 - val_accuracy: 0.7386 - val_precision: 0.6545 - val_recall: 0.9000 - val_auc: 0.8599 - val_f1_score: 0.7579 - val_mcc: 0.5185 - val_balanced_acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 140s 13s/step - loss: 5.2267 - accuracy: 0.7400 - precision: 0.7156 - recall: 0.8297 - auc: 0.8128 - f1_score: 0.7684 - mcc: 0.4825 - balanced_acc: 0.8464 - val_loss: 5.1231 - val_accuracy: 0.7386 - val_precision: 0.6545 - val_recall: 0.9000 - val_auc: 0.8589 - val_f1_score: 0.7579 - val_mcc: 0.5185 - val_balanced_acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 155s 14s/step - loss: 5.0740 - accuracy: 0.7629 - precision: 0.7240 - recall: 0.8791 - auc: 0.8096 - f1_score: 0.7940 - mcc: 0.5344 - balanced_acc: 0.8622 - val_loss: 4.9722 - val_accuracy: 0.7386 - val_precision: 0.6545 - val_recall: 0.9000 - val_auc: 0.8609 - val_f1_score: 0.7579 - val_mcc: 0.5185 - val_balanced_acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 154s 14s/step - loss: 4.9231 - accuracy: 0.7400 - precision: 0.7078 - recall: 0.8516 - auc: 0.8075 - f1_score: 0.7731 - mcc: 0.4859 - balanced_acc: 0.8395 - val_loss: 4.8046 - val_accuracy: 0.7500 - val_precision: 0.6875 - val_recall: 0.8250 - val_auc: 0.8622 - val_f1_score: 0.7500 - val_mcc: 0.5125 - val_balanced_acc: 0.8708 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 150s 14s/step - loss: 4.7699 - accuracy: 0.7600 - precision: 0.7356 - recall: 0.8407 - auc: 0.8111 - f1_score: 0.7846 - mcc: 0.5222 - balanced_acc: 0.8340 - val_loss: 4.6707 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.9000 - val_auc: 0.8633 - val_f1_score: 0.7660 - val_mcc: 0.5369 - val_balanced_acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 153s 14s/step - loss: 4.6367 - accuracy: 0.7457 - precision: 0.6962 - recall: 0.9066 - auc: 0.8016 - f1_score: 0.7876 - mcc: 0.5108 - balanced_acc: 0.8610 - val_loss: 4.5271 - val_accuracy: 0.7614 - val_precision: 0.6863 - val_recall: 0.8750 - val_auc: 0.8661 - val_f1_score: 0.7692 - val_mcc: 0.5464 - val_balanced_acc: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 176s 15s/step - loss: 4.4874 - accuracy: 0.7657 - precision: 0.7427 - recall: 0.8407 - auc: 0.8230 - f1_score: 0.7887 - mcc: 0.5332 - balanced_acc: 0.8489 - val_loss: 4.3927 - val_accuracy: 0.7727 - val_precision: 0.6923 - val_recall: 0.9000 - val_auc: 0.8661 - val_f1_score: 0.7826 - val_mcc: 0.5739 - val_balanced_acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 169s 15s/step - loss: 4.3597 - accuracy: 0.7543 - precision: 0.7051 - recall: 0.9066 - auc: 0.8191 - f1_score: 0.7933 - mcc: 0.5263 - balanced_acc: 0.8759 - val_loss: 4.2738 - val_accuracy: 0.7614 - val_precision: 0.6727 - val_recall: 0.9250 - val_auc: 0.8643 - val_f1_score: 0.7789 - val_mcc: 0.5657 - val_balanced_acc: 0.9312 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 164s 15s/step - loss: 4.2286 - accuracy: 0.7657 - precision: 0.7273 - recall: 0.8791 - auc: 0.8188 - f1_score: 0.7960 - mcc: 0.5397 - balanced_acc: 0.8503 - val_loss: 4.1393 - val_accuracy: 0.7614 - val_precision: 0.6863 - val_recall: 0.8750 - val_auc: 0.8628 - val_f1_score: 0.7692 - val_mcc: 0.5464 - val_balanced_acc: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 162s 14s/step - loss: 4.0916 - accuracy: 0.7571 - precision: 0.7175 - recall: 0.8791 - auc: 0.8321 - f1_score: 0.7901 - mcc: 0.5238 - balanced_acc: 0.8681 - val_loss: 4.0312 - val_accuracy: 0.7500 - val_precision: 0.6607 - val_recall: 0.9250 - val_auc: 0.8630 - val_f1_score: 0.7708 - val_mcc: 0.5477 - val_balanced_acc: 0.9104 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 159s 14s/step - loss: 3.9886 - accuracy: 0.7514 - precision: 0.7209 - recall: 0.8516 - auc: 0.8246 - f1_score: 0.7809 - mcc: 0.5075 - balanced_acc: 0.8544 - val_loss: 3.9201 - val_accuracy: 0.7500 - val_precision: 0.6552 - val_recall: 0.9500 - val_auc: 0.8664 - val_f1_score: 0.7755 - val_mcc: 0.5602 - val_balanced_acc: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 152s 14s/step - loss: 3.8824 - accuracy: 0.7600 - precision: 0.7149 - recall: 0.8956 - auc: 0.8181 - f1_score: 0.7951 - mcc: 0.5333 - balanced_acc: 0.8793 - val_loss: 3.7765 - val_accuracy: 0.7500 - val_precision: 0.6957 - val_recall: 0.8000 - val_auc: 0.8695 - val_f1_score: 0.7442 - val_mcc: 0.5068 - val_balanced_acc: 0.8687 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "11/11 [==============================] - 168s 15s/step - loss: 3.7621 - accuracy: 0.7857 - precision: 0.7536 - recall: 0.8736 - auc: 0.8225 - f1_score: 0.8092 - mcc: 0.5760 - balanced_acc: 0.8505 - val_loss: 3.6721 - val_accuracy: 0.7727 - val_precision: 0.6923 - val_recall: 0.9000 - val_auc: 0.8786 - val_f1_score: 0.7826 - val_mcc: 0.5739 - val_balanced_acc: 0.9187 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 183s 17s/step - loss: 3.6548 - accuracy: 0.7857 - precision: 0.7635 - recall: 0.8516 - auc: 0.8269 - f1_score: 0.8052 - mcc: 0.5729 - balanced_acc: 0.8306 - val_loss: 3.5855 - val_accuracy: 0.7614 - val_precision: 0.6727 - val_recall: 0.9250 - val_auc: 0.8729 - val_f1_score: 0.7789 - val_mcc: 0.5657 - val_balanced_acc: 0.9312 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 165s 15s/step - loss: 3.5497 - accuracy: 0.7686 - precision: 0.7225 - recall: 0.9011 - auc: 0.8289 - f1_score: 0.8020 - mcc: 0.5505 - balanced_acc: 0.8702 - val_loss: 3.4689 - val_accuracy: 0.7841 - val_precision: 0.6981 - val_recall: 0.9250 - val_auc: 0.8828 - val_f1_score: 0.7957 - val_mcc: 0.6019 - val_balanced_acc: 0.9312 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 154s 14s/step - loss: 3.4499 - accuracy: 0.7857 - precision: 0.7421 - recall: 0.9011 - auc: 0.8321 - f1_score: 0.8139 - mcc: 0.5818 - balanced_acc: 0.8761 - val_loss: 3.3707 - val_accuracy: 0.7841 - val_precision: 0.6909 - val_recall: 0.9500 - val_auc: 0.8919 - val_f1_score: 0.8000 - val_mcc: 0.6128 - val_balanced_acc: 0.9438 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 157s 14s/step - loss: 3.3388 - accuracy: 0.8000 - precision: 0.7523 - recall: 0.9176 - auc: 0.8517 - f1_score: 0.8267 - mcc: 0.6122 - balanced_acc: 0.8963 - val_loss: 3.2655 - val_accuracy: 0.7955 - val_precision: 0.7037 - val_recall: 0.9500 - val_auc: 0.9016 - val_f1_score: 0.8085 - val_mcc: 0.6306 - val_balanced_acc: 0.9438 - lr: 1.0000e-04\n",
      "3/3 [==============================] - 11s 2s/step\n",
      "evaluate result\n",
      "\n",
      "Training Fold 3/5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDist  (None, 1200, 800, 16)     2416      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 1200, 800, 16)     64        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 1200, 200, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 1200, 3200)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1200, 256)         3408896   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 1200, 256)         394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 256)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3822129 (14.58 MB)\n",
      "Trainable params: 3822097 (14.58 MB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 182s 16s/step - loss: 5.9248 - accuracy: 0.7000 - precision: 0.6667 - recall: 0.8268 - auc: 0.7678 - f1_score: 0.7382 - mcc: 0.4090 - balanced_acc: 0.8198 - val_loss: 5.8210 - val_accuracy: 0.6705 - val_precision: 0.8182 - val_recall: 0.4186 - val_auc: 0.8204 - val_f1_score: 0.5538 - val_mcc: 0.3806 - val_balanced_acc: 0.6093 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 158s 14s/step - loss: 5.6886 - accuracy: 0.7514 - precision: 0.7277 - recall: 0.8212 - auc: 0.8136 - f1_score: 0.7717 - mcc: 0.5055 - balanced_acc: 0.8258 - val_loss: 5.5919 - val_accuracy: 0.6932 - val_precision: 0.7000 - val_recall: 0.6512 - val_auc: 0.8204 - val_f1_score: 0.6747 - val_mcc: 0.3860 - val_balanced_acc: 0.7256 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 147s 13s/step - loss: 5.5122 - accuracy: 0.7571 - precision: 0.7327 - recall: 0.8268 - auc: 0.8081 - f1_score: 0.7769 - mcc: 0.5171 - balanced_acc: 0.8286 - val_loss: 5.3989 - val_accuracy: 0.7159 - val_precision: 0.7045 - val_recall: 0.7209 - val_auc: 0.8207 - val_f1_score: 0.7126 - val_mcc: 0.4319 - val_balanced_acc: 0.7605 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 142s 13s/step - loss: 5.3511 - accuracy: 0.7371 - precision: 0.7042 - recall: 0.8380 - auc: 0.7990 - f1_score: 0.7653 - mcc: 0.4809 - balanced_acc: 0.8313 - val_loss: 5.2129 - val_accuracy: 0.7273 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8209 - val_f1_score: 0.7333 - val_mcc: 0.4573 - val_balanced_acc: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 140s 13s/step - loss: 5.1672 - accuracy: 0.7371 - precision: 0.7326 - recall: 0.7654 - auc: 0.8161 - f1_score: 0.7486 - mcc: 0.4740 - balanced_acc: 0.8067 - val_loss: 5.0622 - val_accuracy: 0.7273 - val_precision: 0.7111 - val_recall: 0.7442 - val_auc: 0.8199 - val_f1_score: 0.7273 - val_mcc: 0.4553 - val_balanced_acc: 0.7721 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 151s 14s/step - loss: 4.9952 - accuracy: 0.7400 - precision: 0.7157 - recall: 0.8156 - auc: 0.8179 - f1_score: 0.7624 - mcc: 0.4830 - balanced_acc: 0.8376 - val_loss: 4.8858 - val_accuracy: 0.7273 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8199 - val_f1_score: 0.7333 - val_mcc: 0.4573 - val_balanced_acc: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 148s 13s/step - loss: 4.8417 - accuracy: 0.7457 - precision: 0.7143 - recall: 0.8380 - auc: 0.8110 - f1_score: 0.7712 - mcc: 0.4970 - balanced_acc: 0.8342 - val_loss: 4.7398 - val_accuracy: 0.7273 - val_precision: 0.7111 - val_recall: 0.7442 - val_auc: 0.8202 - val_f1_score: 0.7273 - val_mcc: 0.4553 - val_balanced_acc: 0.7721 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 169s 15s/step - loss: 4.6890 - accuracy: 0.7571 - precision: 0.7260 - recall: 0.8436 - auc: 0.8084 - f1_score: 0.7804 - mcc: 0.5194 - balanced_acc: 0.8341 - val_loss: 4.5826 - val_accuracy: 0.7273 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8214 - val_f1_score: 0.7333 - val_mcc: 0.4573 - val_balanced_acc: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 161s 14s/step - loss: 4.5361 - accuracy: 0.7571 - precision: 0.7350 - recall: 0.8212 - auc: 0.8167 - f1_score: 0.7757 - mcc: 0.5165 - balanced_acc: 0.8258 - val_loss: 4.4315 - val_accuracy: 0.7273 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8248 - val_f1_score: 0.7333 - val_mcc: 0.4573 - val_balanced_acc: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 141s 13s/step - loss: 4.3811 - accuracy: 0.7571 - precision: 0.7304 - recall: 0.8324 - auc: 0.8284 - f1_score: 0.7781 - mcc: 0.5178 - balanced_acc: 0.8548 - val_loss: 4.2917 - val_accuracy: 0.7273 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8238 - val_f1_score: 0.7333 - val_mcc: 0.4573 - val_balanced_acc: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 142s 13s/step - loss: 4.2375 - accuracy: 0.7686 - precision: 0.7227 - recall: 0.8883 - auc: 0.8313 - f1_score: 0.7970 - mcc: 0.5499 - balanced_acc: 0.8740 - val_loss: 4.1562 - val_accuracy: 0.7273 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8230 - val_f1_score: 0.7333 - val_mcc: 0.4573 - val_balanced_acc: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 165s 15s/step - loss: 4.1246 - accuracy: 0.7486 - precision: 0.7156 - recall: 0.8436 - auc: 0.8167 - f1_score: 0.7744 - mcc: 0.5033 - balanced_acc: 0.8545 - val_loss: 4.0289 - val_accuracy: 0.7273 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8276 - val_f1_score: 0.7333 - val_mcc: 0.4573 - val_balanced_acc: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 167s 15s/step - loss: 3.9580 - accuracy: 0.7914 - precision: 0.7500 - recall: 0.8883 - auc: 0.8526 - f1_score: 0.8133 - mcc: 0.5915 - balanced_acc: 0.8857 - val_loss: 3.8898 - val_accuracy: 0.7727 - val_precision: 0.7255 - val_recall: 0.8605 - val_auc: 0.8307 - val_f1_score: 0.7872 - val_mcc: 0.5563 - val_balanced_acc: 0.8413 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 161s 14s/step - loss: 3.8602 - accuracy: 0.7657 - precision: 0.7299 - recall: 0.8603 - auc: 0.8286 - f1_score: 0.7897 - mcc: 0.5384 - balanced_acc: 0.8571 - val_loss: 3.7632 - val_accuracy: 0.7955 - val_precision: 0.7358 - val_recall: 0.9070 - val_auc: 0.8372 - val_f1_score: 0.8125 - val_mcc: 0.6086 - val_balanced_acc: 0.8757 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 148s 13s/step - loss: 3.7430 - accuracy: 0.7829 - precision: 0.7309 - recall: 0.9106 - auc: 0.8320 - f1_score: 0.8109 - mcc: 0.5819 - balanced_acc: 0.8793 - val_loss: 3.6741 - val_accuracy: 0.7386 - val_precision: 0.7273 - val_recall: 0.7442 - val_auc: 0.8364 - val_f1_score: 0.7356 - val_mcc: 0.4774 - val_balanced_acc: 0.7943 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 153s 14s/step - loss: 3.6264 - accuracy: 0.7943 - precision: 0.7716 - recall: 0.8492 - auc: 0.8351 - f1_score: 0.8085 - mcc: 0.5905 - balanced_acc: 0.8573 - val_loss: 3.5506 - val_accuracy: 0.7727 - val_precision: 0.7255 - val_recall: 0.8605 - val_auc: 0.8320 - val_f1_score: 0.7872 - val_mcc: 0.5563 - val_balanced_acc: 0.8525 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 3.5111 - accuracy: 0.7800 - precision: 0.7361 - recall: 0.8883 - auc: 0.8473 - f1_score: 0.8051 - mcc: 0.5707 - balanced_acc: 0.8769 - val_loss: 3.4359 - val_accuracy: 0.7727 - val_precision: 0.7255 - val_recall: 0.8605 - val_auc: 0.8398 - val_f1_score: 0.7872 - val_mcc: 0.5563 - val_balanced_acc: 0.8525 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 3.3946 - accuracy: 0.8114 - precision: 0.7580 - recall: 0.9274 - auc: 0.8609 - f1_score: 0.8342 - mcc: 0.6378 - balanced_acc: 0.9140 - val_loss: 3.3707 - val_accuracy: 0.7273 - val_precision: 0.7317 - val_recall: 0.6977 - val_auc: 0.8385 - val_f1_score: 0.7143 - val_mcc: 0.4542 - val_balanced_acc: 0.7711 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 134s 12s/step - loss: 3.2841 - accuracy: 0.7943 - precision: 0.7585 - recall: 0.8771 - auc: 0.8630 - f1_score: 0.8135 - mcc: 0.5946 - balanced_acc: 0.8801 - val_loss: 3.2276 - val_accuracy: 0.7955 - val_precision: 0.7551 - val_recall: 0.8605 - val_auc: 0.8589 - val_f1_score: 0.8043 - val_mcc: 0.5975 - val_balanced_acc: 0.8525 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 117s 10s/step - loss: 3.1761 - accuracy: 0.8200 - precision: 0.7816 - recall: 0.8994 - auc: 0.8792 - f1_score: 0.8364 - mcc: 0.6463 - balanced_acc: 0.9029 - val_loss: 3.1065 - val_accuracy: 0.8295 - val_precision: 0.7800 - val_recall: 0.9070 - val_auc: 0.8837 - val_f1_score: 0.8387 - val_mcc: 0.6686 - val_balanced_acc: 0.8868 - lr: 1.0000e-04\n",
      "3/3 [==============================] - 8s 2s/step\n",
      "evaluate result\n",
      "\n",
      "Training Fold 4/5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDist  (None, 1200, 800, 16)     2416      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 1200, 800, 16)     64        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 1200, 200, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 1200, 3200)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1200, 256)         3408896   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 1200, 256)         394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 256)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3822129 (14.58 MB)\n",
      "Trainable params: 3822097 (14.58 MB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 155s 14s/step - loss: 5.8859 - accuracy: 0.7208 - precision: 0.6816 - recall: 0.8492 - auc: 0.7864 - f1_score: 0.7562 - mcc: 0.4532 - balanced_acc: 0.8287 - val_loss: 5.8484 - val_accuracy: 0.6207 - val_precision: 0.8571 - val_recall: 0.2791 - val_auc: 0.7978 - val_f1_score: 0.4211 - val_mcc: 0.3179 - val_balanced_acc: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 139s 12s/step - loss: 5.6564 - accuracy: 0.7407 - precision: 0.7340 - recall: 0.7709 - auc: 0.8132 - f1_score: 0.7520 - mcc: 0.4814 - balanced_acc: 0.8070 - val_loss: 5.6035 - val_accuracy: 0.6782 - val_precision: 0.6829 - val_recall: 0.6512 - val_auc: 0.7997 - val_f1_score: 0.6667 - val_mcc: 0.3563 - val_balanced_acc: 0.7460 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 139s 12s/step - loss: 5.4551 - accuracy: 0.7521 - precision: 0.6933 - recall: 0.9218 - auc: 0.8283 - f1_score: 0.7914 - mcc: 0.5322 - balanced_acc: 0.8940 - val_loss: 5.4014 - val_accuracy: 0.7241 - val_precision: 0.7111 - val_recall: 0.7442 - val_auc: 0.8023 - val_f1_score: 0.7273 - val_mcc: 0.4490 - val_balanced_acc: 0.7925 - lr: 1.0000e-04\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 132s 12s/step - loss: 5.2684 - accuracy: 0.7550 - precision: 0.7313 - recall: 0.8212 - auc: 0.8252 - f1_score: 0.7737 - mcc: 0.5126 - balanced_acc: 0.8408 - val_loss: 5.2166 - val_accuracy: 0.7011 - val_precision: 0.6977 - val_recall: 0.6977 - val_auc: 0.8026 - val_f1_score: 0.6977 - val_mcc: 0.4022 - val_balanced_acc: 0.7693 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 140s 13s/step - loss: 5.0922 - accuracy: 0.7664 - precision: 0.7343 - recall: 0.8492 - auc: 0.8160 - f1_score: 0.7876 - mcc: 0.5380 - balanced_acc: 0.8345 - val_loss: 5.0327 - val_accuracy: 0.7586 - val_precision: 0.7200 - val_recall: 0.8372 - val_auc: 0.8013 - val_f1_score: 0.7742 - val_mcc: 0.5249 - val_balanced_acc: 0.8391 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 4.9048 - accuracy: 0.7664 - precision: 0.7256 - recall: 0.8715 - auc: 0.8303 - f1_score: 0.7919 - mcc: 0.5423 - balanced_acc: 0.8805 - val_loss: 4.8606 - val_accuracy: 0.7241 - val_precision: 0.7111 - val_recall: 0.7442 - val_auc: 0.8023 - val_f1_score: 0.7273 - val_mcc: 0.4490 - val_balanced_acc: 0.7925 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 134s 12s/step - loss: 4.7421 - accuracy: 0.7493 - precision: 0.7264 - recall: 0.8156 - auc: 0.8264 - f1_score: 0.7684 - mcc: 0.5011 - balanced_acc: 0.8322 - val_loss: 4.6934 - val_accuracy: 0.7471 - val_precision: 0.7143 - val_recall: 0.8140 - val_auc: 0.8036 - val_f1_score: 0.7609 - val_mcc: 0.4997 - val_balanced_acc: 0.8388 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 140s 13s/step - loss: 4.5681 - accuracy: 0.7635 - precision: 0.7143 - recall: 0.8939 - auc: 0.8333 - f1_score: 0.7940 - mcc: 0.5428 - balanced_acc: 0.8859 - val_loss: 4.5383 - val_accuracy: 0.7241 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8021 - val_f1_score: 0.7333 - val_mcc: 0.4507 - val_balanced_acc: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 4.3959 - accuracy: 0.8006 - precision: 0.7583 - recall: 0.8939 - auc: 0.8485 - f1_score: 0.8205 - mcc: 0.6098 - balanced_acc: 0.8830 - val_loss: 4.3830 - val_accuracy: 0.7471 - val_precision: 0.7143 - val_recall: 0.8140 - val_auc: 0.8095 - val_f1_score: 0.7609 - val_mcc: 0.4997 - val_balanced_acc: 0.8274 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 139s 13s/step - loss: 4.2515 - accuracy: 0.7607 - precision: 0.7111 - recall: 0.8939 - auc: 0.8457 - f1_score: 0.7921 - mcc: 0.5377 - balanced_acc: 0.8888 - val_loss: 4.2387 - val_accuracy: 0.7241 - val_precision: 0.7021 - val_recall: 0.7674 - val_auc: 0.8050 - val_f1_score: 0.7333 - val_mcc: 0.4507 - val_balanced_acc: 0.8042 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 139s 13s/step - loss: 4.1253 - accuracy: 0.7835 - precision: 0.7309 - recall: 0.9106 - auc: 0.8298 - f1_score: 0.8109 - mcc: 0.5834 - balanced_acc: 0.8914 - val_loss: 4.0861 - val_accuracy: 0.7701 - val_precision: 0.7255 - val_recall: 0.8605 - val_auc: 0.8081 - val_f1_score: 0.7872 - val_mcc: 0.5505 - val_balanced_acc: 0.8507 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 138s 12s/step - loss: 3.9761 - accuracy: 0.7778 - precision: 0.7590 - recall: 0.8268 - auc: 0.8499 - f1_score: 0.7914 - mcc: 0.5569 - balanced_acc: 0.8611 - val_loss: 3.9430 - val_accuracy: 0.7701 - val_precision: 0.7170 - val_recall: 0.8837 - val_auc: 0.8132 - val_f1_score: 0.7917 - val_mcc: 0.5562 - val_balanced_acc: 0.8623 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 135s 12s/step - loss: 3.8371 - accuracy: 0.7835 - precision: 0.7269 - recall: 0.9218 - auc: 0.8467 - f1_score: 0.8128 - mcc: 0.5871 - balanced_acc: 0.8940 - val_loss: 3.8204 - val_accuracy: 0.7701 - val_precision: 0.7255 - val_recall: 0.8605 - val_auc: 0.8137 - val_f1_score: 0.7872 - val_mcc: 0.5505 - val_balanced_acc: 0.8507 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 138s 12s/step - loss: 3.7188 - accuracy: 0.7664 - precision: 0.7235 - recall: 0.8771 - auc: 0.8450 - f1_score: 0.7929 - mcc: 0.5436 - balanced_acc: 0.8717 - val_loss: 3.6864 - val_accuracy: 0.7816 - val_precision: 0.7308 - val_recall: 0.8837 - val_auc: 0.8216 - val_f1_score: 0.8000 - val_mcc: 0.5766 - val_balanced_acc: 0.8623 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 3.5866 - accuracy: 0.7920 - precision: 0.7573 - recall: 0.8715 - auc: 0.8618 - f1_score: 0.8104 - mcc: 0.5897 - balanced_acc: 0.8689 - val_loss: 3.5559 - val_accuracy: 0.7816 - val_precision: 0.7400 - val_recall: 0.8605 - val_auc: 0.8377 - val_f1_score: 0.7957 - val_mcc: 0.5714 - val_balanced_acc: 0.8621 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 136s 12s/step - loss: 3.4526 - accuracy: 0.8063 - precision: 0.7707 - recall: 0.8827 - auc: 0.8801 - f1_score: 0.8229 - mcc: 0.6181 - balanced_acc: 0.8977 - val_loss: 3.4493 - val_accuracy: 0.7816 - val_precision: 0.7400 - val_recall: 0.8605 - val_auc: 0.8383 - val_f1_score: 0.7957 - val_mcc: 0.5714 - val_balanced_acc: 0.8734 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 134s 12s/step - loss: 3.3255 - accuracy: 0.8234 - precision: 0.7696 - recall: 0.9330 - auc: 0.8950 - f1_score: 0.8434 - mcc: 0.6609 - balanced_acc: 0.9287 - val_loss: 3.3274 - val_accuracy: 0.7816 - val_precision: 0.7400 - val_recall: 0.8605 - val_auc: 0.8502 - val_f1_score: 0.7957 - val_mcc: 0.5714 - val_balanced_acc: 0.8848 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 136s 12s/step - loss: 3.2400 - accuracy: 0.8291 - precision: 0.7793 - recall: 0.9274 - auc: 0.8834 - f1_score: 0.8469 - mcc: 0.6694 - balanced_acc: 0.9172 - val_loss: 3.2204 - val_accuracy: 0.7701 - val_precision: 0.7556 - val_recall: 0.7907 - val_auc: 0.8644 - val_f1_score: 0.7727 - val_mcc: 0.5410 - val_balanced_acc: 0.8158 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 3.1117 - accuracy: 0.8490 - precision: 0.8247 - recall: 0.8939 - auc: 0.9067 - f1_score: 0.8579 - mcc: 0.6999 - balanced_acc: 0.9033 - val_loss: 3.0953 - val_accuracy: 0.7931 - val_precision: 0.7660 - val_recall: 0.8372 - val_auc: 0.8924 - val_f1_score: 0.8000 - val_mcc: 0.5891 - val_balanced_acc: 0.8732 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 120s 11s/step - loss: 2.9877 - accuracy: 0.8519 - precision: 0.8223 - recall: 0.9050 - auc: 0.9375 - f1_score: 0.8617 - mcc: 0.7067 - balanced_acc: 0.9380 - val_loss: 2.9942 - val_accuracy: 0.8276 - val_precision: 0.7800 - val_recall: 0.9070 - val_auc: 0.8964 - val_f1_score: 0.8387 - val_mcc: 0.6644 - val_balanced_acc: 0.9080 - lr: 1.0000e-04\n",
      "3/3 [==============================] - 8s 2s/step\n",
      "evaluate result\n",
      "\n",
      "Training Fold 5/5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDist  (None, 1200, 800, 16)     2416      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 1200, 800, 16)     64        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 1200, 200, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 1200, 3200)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1200, 256)         3408896   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 1200, 256)         394240    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1200, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 256)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3822129 (14.58 MB)\n",
      "Trainable params: 3822097 (14.58 MB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 147s 13s/step - loss: 5.9168 - accuracy: 0.6980 - precision: 0.6353 - recall: 0.9257 - auc: 0.7762 - f1_score: 0.7535 - mcc: 0.4456 - balanced_acc: 0.8776 - val_loss: 5.8294 - val_accuracy: 0.7011 - val_precision: 0.7838 - val_recall: 0.6170 - val_auc: 0.8226 - val_f1_score: 0.6905 - val_mcc: 0.4204 - val_balanced_acc: 0.7335 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 138s 12s/step - loss: 5.6445 - accuracy: 0.7322 - precision: 0.7213 - recall: 0.7543 - auc: 0.8262 - f1_score: 0.7374 - mcc: 0.4649 - balanced_acc: 0.8033 - val_loss: 5.5574 - val_accuracy: 0.7356 - val_precision: 0.7500 - val_recall: 0.7660 - val_auc: 0.8247 - val_f1_score: 0.7579 - val_mcc: 0.4670 - val_balanced_acc: 0.8080 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 131s 12s/step - loss: 5.4538 - accuracy: 0.7436 - precision: 0.7202 - recall: 0.7943 - auc: 0.8083 - f1_score: 0.7554 - mcc: 0.4899 - balanced_acc: 0.8233 - val_loss: 5.3374 - val_accuracy: 0.7701 - val_precision: 0.7288 - val_recall: 0.9149 - val_auc: 0.8234 - val_f1_score: 0.8113 - val_mcc: 0.5493 - val_balanced_acc: 0.8824 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 131s 12s/step - loss: 5.2439 - accuracy: 0.7350 - precision: 0.6990 - recall: 0.8229 - auc: 0.8152 - f1_score: 0.7559 - mcc: 0.4779 - balanced_acc: 0.8347 - val_loss: 5.1422 - val_accuracy: 0.7586 - val_precision: 0.7167 - val_recall: 0.9149 - val_auc: 0.8237 - val_f1_score: 0.8037 - val_mcc: 0.5277 - val_balanced_acc: 0.8824 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 5.0542 - accuracy: 0.7607 - precision: 0.7514 - recall: 0.7771 - auc: 0.8229 - f1_score: 0.7640 - mcc: 0.5217 - balanced_acc: 0.8175 - val_loss: 4.9544 - val_accuracy: 0.7586 - val_precision: 0.7321 - val_recall: 0.8723 - val_auc: 0.8237 - val_f1_score: 0.7961 - val_mcc: 0.5176 - val_balanced_acc: 0.8612 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 4.8825 - accuracy: 0.7550 - precision: 0.7214 - recall: 0.8286 - auc: 0.8132 - f1_score: 0.7713 - mcc: 0.5159 - balanced_acc: 0.8319 - val_loss: 4.7779 - val_accuracy: 0.7701 - val_precision: 0.7368 - val_recall: 0.8936 - val_auc: 0.8247 - val_f1_score: 0.8077 - val_mcc: 0.5438 - val_balanced_acc: 0.8718 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 141s 13s/step - loss: 4.7005 - accuracy: 0.7436 - precision: 0.7053 - recall: 0.8343 - auc: 0.8169 - f1_score: 0.7644 - mcc: 0.4957 - balanced_acc: 0.8433 - val_loss: 4.6104 - val_accuracy: 0.7586 - val_precision: 0.7167 - val_recall: 0.9149 - val_auc: 0.8271 - val_f1_score: 0.8037 - val_mcc: 0.5277 - val_balanced_acc: 0.8824 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 4.5332 - accuracy: 0.7322 - precision: 0.7143 - recall: 0.7714 - auc: 0.8253 - f1_score: 0.7418 - mcc: 0.4660 - balanced_acc: 0.8232 - val_loss: 4.4482 - val_accuracy: 0.7816 - val_precision: 0.7414 - val_recall: 0.9149 - val_auc: 0.8271 - val_f1_score: 0.8190 - val_mcc: 0.5708 - val_balanced_acc: 0.8824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 137s 12s/step - loss: 4.3806 - accuracy: 0.7436 - precision: 0.7297 - recall: 0.7714 - auc: 0.8193 - f1_score: 0.7500 - mcc: 0.4881 - balanced_acc: 0.8204 - val_loss: 4.2998 - val_accuracy: 0.7471 - val_precision: 0.7049 - val_recall: 0.9149 - val_auc: 0.8245 - val_f1_score: 0.7963 - val_mcc: 0.5062 - val_balanced_acc: 0.8949 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 135s 12s/step - loss: 4.2373 - accuracy: 0.7493 - precision: 0.6916 - recall: 0.8971 - auc: 0.8232 - f1_score: 0.7811 - mcc: 0.5224 - balanced_acc: 0.8804 - val_loss: 4.1485 - val_accuracy: 0.7816 - val_precision: 0.7414 - val_recall: 0.9149 - val_auc: 0.8255 - val_f1_score: 0.8190 - val_mcc: 0.5708 - val_balanced_acc: 0.8824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 135s 12s/step - loss: 4.0722 - accuracy: 0.7493 - precision: 0.7326 - recall: 0.7829 - auc: 0.8353 - f1_score: 0.7569 - mcc: 0.4998 - balanced_acc: 0.8147 - val_loss: 4.0050 - val_accuracy: 0.7471 - val_precision: 0.7273 - val_recall: 0.8511 - val_auc: 0.8277 - val_f1_score: 0.7843 - val_mcc: 0.4920 - val_balanced_acc: 0.8755 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 139s 13s/step - loss: 3.9451 - accuracy: 0.7664 - precision: 0.7313 - recall: 0.8400 - auc: 0.8285 - f1_score: 0.7819 - mcc: 0.5389 - balanced_acc: 0.8575 - val_loss: 3.8700 - val_accuracy: 0.7816 - val_precision: 0.7414 - val_recall: 0.9149 - val_auc: 0.8306 - val_f1_score: 0.8190 - val_mcc: 0.5708 - val_balanced_acc: 0.9074 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 138s 12s/step - loss: 3.8060 - accuracy: 0.7721 - precision: 0.7317 - recall: 0.8571 - auc: 0.8293 - f1_score: 0.7895 - mcc: 0.5525 - balanced_acc: 0.8604 - val_loss: 3.7433 - val_accuracy: 0.7701 - val_precision: 0.7213 - val_recall: 0.9362 - val_auc: 0.8309 - val_f1_score: 0.8148 - val_mcc: 0.5565 - val_balanced_acc: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 133s 12s/step - loss: 3.6994 - accuracy: 0.7578 - precision: 0.7103 - recall: 0.8686 - auc: 0.8166 - f1_score: 0.7815 - mcc: 0.5292 - balanced_acc: 0.8604 - val_loss: 3.6184 - val_accuracy: 0.7816 - val_precision: 0.7333 - val_recall: 0.9362 - val_auc: 0.8338 - val_f1_score: 0.8224 - val_mcc: 0.5776 - val_balanced_acc: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 133s 12s/step - loss: 3.5681 - accuracy: 0.7635 - precision: 0.7190 - recall: 0.8629 - auc: 0.8313 - f1_score: 0.7844 - mcc: 0.5381 - balanced_acc: 0.8718 - val_loss: 3.5069 - val_accuracy: 0.7471 - val_precision: 0.6984 - val_recall: 0.9362 - val_auc: 0.8340 - val_f1_score: 0.8000 - val_mcc: 0.5142 - val_balanced_acc: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 142s 13s/step - loss: 3.4423 - accuracy: 0.7607 - precision: 0.7177 - recall: 0.8571 - auc: 0.8439 - f1_score: 0.7812 - mcc: 0.5317 - balanced_acc: 0.8661 - val_loss: 3.3900 - val_accuracy: 0.7816 - val_precision: 0.7333 - val_recall: 0.9362 - val_auc: 0.8386 - val_f1_score: 0.8224 - val_mcc: 0.5776 - val_balanced_acc: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 135s 12s/step - loss: 3.3571 - accuracy: 0.7493 - precision: 0.7377 - recall: 0.7714 - auc: 0.8259 - f1_score: 0.7542 - mcc: 0.4992 - balanced_acc: 0.8147 - val_loss: 3.2916 - val_accuracy: 0.7931 - val_precision: 0.7458 - val_recall: 0.9362 - val_auc: 0.8348 - val_f1_score: 0.8302 - val_mcc: 0.5986 - val_balanced_acc: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 143s 13s/step - loss: 3.2575 - accuracy: 0.7379 - precision: 0.6895 - recall: 0.8629 - auc: 0.8217 - f1_score: 0.7665 - mcc: 0.4918 - balanced_acc: 0.8576 - val_loss: 3.1917 - val_accuracy: 0.7816 - val_precision: 0.7414 - val_recall: 0.9149 - val_auc: 0.8348 - val_f1_score: 0.8190 - val_mcc: 0.5708 - val_balanced_acc: 0.9074 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "11/11 [==============================] - 135s 12s/step - loss: 3.1373 - accuracy: 0.7721 - precision: 0.7540 - recall: 0.8057 - auc: 0.8462 - f1_score: 0.7790 - mcc: 0.5455 - balanced_acc: 0.8404 - val_loss: 3.0932 - val_accuracy: 0.7931 - val_precision: 0.7544 - val_recall: 0.9149 - val_auc: 0.8364 - val_f1_score: 0.8269 - val_mcc: 0.5923 - val_balanced_acc: 0.8949 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 120s 11s/step - loss: 3.0605 - accuracy: 0.7749 - precision: 0.7330 - recall: 0.8629 - auc: 0.8275 - f1_score: 0.7927 - mcc: 0.5589 - balanced_acc: 0.8490 - val_loss: 3.0026 - val_accuracy: 0.7931 - val_precision: 0.7636 - val_recall: 0.8936 - val_auc: 0.8386 - val_f1_score: 0.8235 - val_mcc: 0.5877 - val_balanced_acc: 0.8968 - lr: 1.0000e-04\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1647836a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 9s 2s/step\n",
      "evaluate result\n",
      "\n",
      "所有交叉验证轮次完成！\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras import backend as K\n",
    "from keras.metrics import Precision, Recall, AUC\n",
    "import time\n",
    "import pickle\n",
    "from keras.layers import LayerNormalization, MultiHeadAttention, GlobalMaxPooling1D, ReLU, BatchNormalization, Attention, Reshape, Conv1D, GlobalAveragePooling1D, Dense, Input, MultiHeadAttention\n",
    "\n",
    "current_seed = 1028\n",
    "print(current_seed)\n",
    "k = 5  # 折数\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=1028)\n",
    "histories = []\n",
    "\n",
    "cross_val_results = {\n",
    "    'config': {\n",
    "        'seed': current_seed,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        # 其他配置参数...\n",
    "    },\n",
    "    'folds': []\n",
    "}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(x_train)):\n",
    "    print(f\"\\nTraining Fold {fold+1}/{k}\")\n",
    "    \n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(TimeDistributed(Conv1D(16, kernel_size=25, activation='relu', \n",
    "           padding='same',\n",
    "           kernel_initializer='he_normal'),\n",
    "              input_shape=x_train.shape[1:]))\n",
    "    model.add(TimeDistributed(BatchNormalization(momentum=0.95)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(4)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.002))))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.002))))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.005)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = [\n",
    "                      'accuracy', \n",
    "                      Precision(name='precision'), \n",
    "                      Recall(name='recall'),\n",
    "                      AUC(name='auc'),\n",
    "                      F1Score(),\n",
    "                      MatthewsCorrelationCoefficient(name='mcc'),\n",
    "                      BalancedAccuracy()])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                  factor = reduce_lr_factor,\n",
    "                                  patience = reduce_lr_patience,\n",
    "                                  min_lr = min_learning_rate)\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = early_stopping_patience)\n",
    "    \n",
    "    x_val_fold = x_train[val_idx]\n",
    "    y_val_fold = y_train[val_idx]\n",
    "\n",
    "    history = model.fit(x_train[train_idx], y_train[train_idx],\n",
    "                        validation_data=(x_val_fold, y_val_fold), \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = epochs,\n",
    "                        callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "    \n",
    "    y_pred_probs = model.predict(x_val_fold).flatten()\n",
    "    \n",
    "    fold_data = {\n",
    "        'fold_number': fold+1,\n",
    "        'train_indices': train_idx,\n",
    "        'val_indices': val_idx,\n",
    "        'history': history.history,\n",
    "        'best_epoch': best_epoch,\n",
    "        'y_true': y_val_fold,\n",
    "        'y_pred_probs': y_pred_probs,\n",
    "        'final_metrics': dict(zip(\n",
    "            model.metrics_names,\n",
    "            model.evaluate(x_val_fold, y_val_fold, verbose=0)\n",
    "        ))\n",
    "    }\n",
    "    \n",
    "    model.save(f'conv_bilstm_fold_{fold+1}.keras')\n",
    "    with open(f'conv_bilstm_fold_{fold+1}_data.pkl', 'wb') as f:\n",
    "        pickle.dump(fold_data, f)\n",
    "    \n",
    "    cross_val_results['folds'].append(fold_data)\n",
    "\n",
    "    print(\"evaluate result\")\n",
    "    model.evaluate(x_train[val_idx], y_train[val_idx], verbose=0)\n",
    "    with open(f'conv_bilstm_fold_{fold+1}_history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "        \n",
    "    model.save(r'conv_bilstm_fold_'+str(fold+1) +'.keras')\n",
    "        \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "with open('conv_bilstm_validation_results.pkl', 'wb') as f:\n",
    "    pickle.dump(cross_val_results, f)\n",
    "print(\"\\n所有交叉验证轮次完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
